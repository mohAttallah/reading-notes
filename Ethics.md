# Ethics

## Cybersecurity Risks in Self-Driving Cars

**1. Growing Concerns:**
Anticipated surge in self-driving cars raises cybersecurity worries, including potential remote hijacking, terror threats, and data breaches.

**2. Vulnerability to Hacking:**
Complexity and connectivity make self-driving cars susceptible to hacking, especially if reliant on external sensors and cloud computing.

**3. Automaker Responses:**
Car manufacturers address vulnerabilities by reducing software flaws and segregating computer networks within vehicles.

**4. Government and Startups:**
Government regulators should ensure secure coding practices, while startups aim to protect autonomous cars from cyberattacks.

**5. Trust in Self-Driving Cars:**
Complete trust in fully autonomous vehicles is currently limited; confidence may grow as technology matures.


## AI at Google: our principles

**1. Social Benefit:**
Google's AI development aims to benefit society and respects cultural, social, and legal norms. The overall benefits must outweigh potential risks.

**2. Bias Avoidance:**
Google commits to preventing and reducing unfair biases, especially those related to sensitive characteristics like race, gender, and more.

**3. Safety Priority:**
Strong safety and security practices are applied to AI development to prevent unintended harmful outcomes.

**4. Accountability:**
Google's AI systems will provide opportunities for feedback, explanations, and human direction.

**5. Privacy Integration:**
Privacy principles are integrated into AI development, including notice, consent, safeguards, transparency, and data control.

**6. Scientific Excellence:**
Google strives for scientific rigor and openness in AI research, promoting multidisciplinary approaches and sharing knowledge.

**7. Responsible Use:**
Google evaluates AI applications based on purpose, uniqueness, scale, and the nature of its involvement.



